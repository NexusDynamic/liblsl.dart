@article{blumEEGRecordingOnline2017a,
  title = {{{EEG Recording}} and {{Online Signal Processing}} on {{Android}}: {{A Multiapp Framework}} for {{Brain-Computer Interfaces}} on {{Smartphone}}},
  shorttitle = {{{EEG Recording}} and {{Online Signal Processing}} on {{Android}}},
  author = {Blum, Sarah and Debener, Stefan and Emkes, Reiner and Volkening, Nils and Fudickar, Sebastian and Bleichner, Martin G.},
  year = {2017},
  journal = {BioMed Research International},
  volume = {2017},
  number = {1},
  pages = {3072870},
  issn = {2314-6141},
  doi = {10.1155/2017/3072870},
  urldate = {2025-10-10},
  abstract = {Objective. Our aim was the development and validation of a modular signal processing and classification application enabling online electroencephalography (EEG) signal processing on off-the-shelf mobile Android devices. The software application SCALA (Signal ProCessing and CLassification on Android) supports a standardized communication interface to exchange information with external software and hardware. Approach. In order to implement a closed-loop brain-computer interface (BCI) on the smartphone, we used a multiapp framework, which integrates applications for stimulus presentation, data acquisition, data processing, classification, and delivery of feedback to the user. Main Results. We have implemented the open source signal processing application SCALA. We present timing test results supporting sufficient temporal precision of audio events. We also validate SCALA with a well-established auditory selective attention paradigm and report above chance level classification results for all participants. Regarding the 24-channel EEG signal quality, evaluation results confirm typical sound onset auditory evoked potentials as well as cognitive event-related potentials that differentiate between correct and incorrect task performance feedback. Significance. We present a fully smartphone-operated, modular closed-loop BCI system that can be combined with different EEG amplifiers and can easily implement other paradigms.},
  copyright = {Copyright {\copyright} 2017 Sarah Blum et al.},
  langid = {english},
  file = {/Users/au662726/Zotero/storage/TBJ9YUTV/Blum et al. - 2017 - EEG Recording and Online Signal Processing on Android A Multiapp Framework for Brain-Computer Inter.pdf;/Users/au662726/Zotero/storage/APKUUR6R/3072870.html}
}

@book{boggioSocialAffectiveNeuroscience2023,
  title = {Social and {{Affective Neuroscience}} of {{Everyday Human Interaction}}: {{From Theory}} to {{Methodology}}},
  shorttitle = {Social and {{Affective Neuroscience}} of {{Everyday Human Interaction}}},
  editor = {Boggio, Paulo S{\'e}rgio and Wingenbach, Tanja S. H. and Da Silveira Co{\^e}lho, Mar{\'i}lia Lira and Comfort, William Edgar and Murrins Marques, Lucas and Alves, Marcus Vinicius C.},
  year = {2023},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-08651-9},
  urldate = {2025-10-10},
  copyright = {https://creativecommons.org/licenses/by/4.0},
  isbn = {978-3-031-08650-2 978-3-031-08651-9},
  langid = {english},
  file = {/Users/au662726/Zotero/storage/LAGSP4VC/Boggio et al. - 2023 - Social and Affective Neuroscience of Everyday Human Interaction From Theory to Methodology.pdf}
}

@article{debenerUnobtrusiveAmbulatoryEEG2015,
  title = {Unobtrusive Ambulatory {{EEG}} Using a Smartphone and Flexible Printed Electrodes around the Ear},
  author = {Debener, Stefan and Emkes, Reiner and De Vos, Maarten and Bleichner, Martin},
  year = {2015},
  month = nov,
  journal = {Scientific Reports},
  volume = {5},
  number = {1},
  pages = {16743},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/srep16743},
  urldate = {2025-10-10},
  abstract = {This study presents first evidence that reliable EEG data can be recorded with a new cEEGrid electrode array, which consists of ten electrodes printed on flexible sheet and arranged in a c-shape to fit around the ear. Ten participants wore two cEEGrid systems for at least seven hours. Using a smartphone for stimulus delivery and signal acquisition, resting EEG and auditory oddball data were collected in the morning and in the afternoon six to seven hours apart. Analysis of resting EEG data confirmed well-known spectral differences between eyes open and eyes closed conditions. The ERP results confirmed the predicted condition effects with significantly larger P300 amplitudes for target compared to standard tones and a high test-retest reliability of the P300 amplitude (r\,{$>$}\,=\,.74). Moreover, a linear classifier trained on data from the morning session revealed similar performance in classification accuracy for the morning and the afternoon sessions (both\,{$>$}\,70\%). These findings demonstrate the feasibility of concealed and comfortable brain activity acquisition over many hours.},
  copyright = {2015 The Author(s)},
  langid = {english},
  keywords = {Neuroscience,Psychology},
  file = {/Users/au662726/Zotero/storage/CY72XRUA/Debener et al. - 2015 - Unobtrusive ambulatory EEG using a smartphone and flexible printed electrodes around the ear.pdf}
}

@inproceedings{demazureDistributedRemoteEEG2021,
  title = {Distributed {{Remote EEG Data Collection}} for {{NeuroIS Research}}: {{A Methodological Framework}}},
  shorttitle = {Distributed {{Remote EEG Data Collection}} for {{NeuroIS Research}}},
  booktitle = {Augmented {{Cognition}}},
  author = {Demazure, Th{\'e}ophile and Karran, Alexander J. and Boasen, Jared and L{\'e}ger, Pierre-Majorique and S{\'e}n{\'e}cal, Sylvain},
  editor = {Schmorrow, Dylan D. and Fidopiastis, Cali M.},
  year = {2021},
  pages = {3--22},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-78114-9_1},
  abstract = {Remote electroencephalography (EEG) studies offers the exciting opportunity to gather data within a participants' home environment. However, remote EEG data collection trades some internal validity for ecological validity. When interacting with interfaces or other artifacts in remote settings, neurophysiological responses and behaviour may display distinct differences compared to laboratory studies. We propose a methodological approach composed of several recommendations and an iterative process framework to support this new avenue of research. The framework was developed during workshops composed of a diverse panel and a literature review of relevant research to complement our discoveries. We highlight and discuss the significant challenges associated with remote EEG data collection, and propose recommendations. We introduce the concept of self-applicability and propose a set of measures to guarantee good signal quality. Additionally, we offer specific recommendations for research design, training, and data collection strategies. We offer the iterative process framework to provide support rigorous data collection, innovative research questions, and the construction of large-scale datasets from remote EEG studies.},
  isbn = {978-3-030-78114-9},
  langid = {english},
  keywords = {Electroencephalography,Human-computer interaction,Methodology,Real-world,Remote experiment}
}

@article{dolmans2020data,
  title = {Data Synchronisation and Processing in Multimodal Research},
  author = {Dolmans, {\relax TC} and Poel, M and {van't Klooster}, {\relax JWJR} and Veldkamp, {\relax BP}},
  year = {2020},
  journal = {Measuring Behavior 2020-21 Volume},
  volume = {1},
  pages = {26--32}
}

@article{iwamaTwoCommonIssues2024,
  title = {Two Common Issues in Synchronized Multimodal Recordings with {{EEG}}: {{Jitter}} and Latency},
  shorttitle = {Two Common Issues in Synchronized Multimodal Recordings with {{EEG}}},
  author = {Iwama, Seitaro and Takemi, Mitsuaki and Eguchi, Ryo and Hirose, Ryotaro and Morishige, Masumi and Ushiba, Junichi},
  year = {2024},
  month = jun,
  journal = {Neuroscience Research},
  volume = {203},
  pages = {1--7},
  issn = {01680102},
  doi = {10.1016/j.neures.2023.12.003},
  urldate = {2025-09-19},
  langid = {english},
  file = {/Users/au662726/Zotero/storage/DLE6QY6E/Iwama et al. - 2024 - Two common issues in synchronized multimodal recordings with EEG Jitter and latency.pdf}
}

@article{kotheLabStreamingLayer2025,
  title = {The Lab Streaming Layer for Synchronized Multimodal Recording},
  author = {Kothe, Christian and Shirazi, Seyed Yahya and Stenner, Tristan and Medine, David and Boulay, Chadwick and Grivich, Matthew I. and Artoni, Fiorenzo and Mullen, Tim and Delorme, Arnaud and Makeig, Scott},
  year = {2025},
  month = sep,
  journal = {Imaging Neuroscience},
  volume = {3},
  pages = {IMAG.a.136},
  issn = {2837-6056},
  doi = {10.1162/IMAG.a.136},
  urldate = {2025-09-19},
  abstract = {Abstract             Accurately recording the interactions of humans or other organisms with their environment and other agents requires synchronized data access via multiple instruments, often running independently using different clocks. Active, hardware-mediated solutions are often infeasible or prohibitively costly to build and run across arbitrary collections of input systems. The Lab Streaming Layer (LSL) framework offers a software-based approach to synchronizing data streams based on per-sample time stamps and time synchronization across a common local area network (LAN). Built from the ground up for neurophysiological applications and designed for reliability, LSL offers zero-configuration functionality and accounts for network delays and jitters, making connection recovery, offset correction, and jitter compensation possible. These features can ensure continuous, millisecond-precise data recording, even in the face of interruptions. In this paper, we present an overview of LSL architecture, core features, and performance in common experimental contexts. We also highlight practical considerations and known pitfalls when using LSL, including the need to take into account input device throughput delays that LSL cannot itself measure or correct. The LSL ecosystem has grown to support over 150 data acquisition device classes and to establish interoperability between client software written in several programming languages, including C/C++, Python, MATLAB, Java, C\#, JavaScript, Rust, and Julia. The resilience and versatility of LSL have made it a major data synchronization platform for multimodal human neurobehavioral recording, now supported by a wide range of software packages, including major stimulus presentation tools, real-time analysis environments, and brain-computer interface applications. Beyond basic science, research, and development, LSL has been used as a resilient and transparent back-end in deployment scenarios, including interactive art installations, stage performances, and commercial products. In neurobehavioral studies and other neuroscience applications, LSL facilitates the complex task of capturing organismal dynamics and environmental changes occurring within and across multiple data streams on a common timeline.},
  langid = {english}
}

@misc{LiblslLanguageWrappers,
  title = {Liblsl Language Wrappers --- {{Labstreaminglayer}} 1.13 Documentation},
  author = {Kothe, Christian and Medine, David and Boulay, Chadwick and Grivich, Matthew and Stenner, Tristan},
  year = {2019},
  urldate = {2025-09-23},
  howpublished = {https://labstreaminglayer.readthedocs.io/info/language\_wrappers.html},
  file = {/Users/au662726/Zotero/storage/LD2HD6RJ/language_wrappers.html}
}

@article{luftSocialSynchronizationBrain2022,
  title = {Social Synchronization of Brain Activity Increases during Eye-Contact},
  author = {Luft, Caroline Di Bernardi and Zioga, Ioanna and Giannopoulos, Anastasios and Di Bona, Gabriele and Binetti, Nicola and Civilini, Andrea and Latora, Vito and Mareschal, Isabelle},
  year = {2022},
  month = may,
  journal = {Communications Biology},
  volume = {5},
  number = {1},
  pages = {412},
  publisher = {Nature Publishing Group},
  issn = {2399-3642},
  doi = {10.1038/s42003-022-03352-6},
  urldate = {2025-10-10},
  abstract = {Humans make eye-contact to extract information about other people's mental states, recruiting dedicated brain networks that process information about the self and others. Recent studies show that eye-contact increases the synchronization between two brains but do not consider its effects on activity within single brains. Here we investigate how eye-contact affects the frequency and direction of the synchronization within and between two brains and the corresponding network characteristics. We also evaluate the functional relevance of eye-contact networks by comparing inter- and intra-brain networks of friends vs. strangers and the direction of synchronization between leaders and followers. We show that eye-contact increases higher inter- and intra-brain synchronization in the gamma frequency band. Network analysis reveals that some brain areas serve as hubs linking within- and between-brain networks. During eye-contact, friends show higher inter-brain synchronization than strangers. Dyads with clear leader/follower roles demonstrate higher synchronization from leader to follower in the alpha frequency band. Importantly, eye-contact affects synchronization between brains more than within brains, demonstrating that eye-contact is an inherently social signal. Future work should elucidate the causal mechanisms behind eye-contact induced synchronization.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Cognitive neuroscience,Cooperation,Social neuroscience},
  file = {/Users/au662726/Zotero/storage/U5PEIBX5/Luft et al. - 2022 - Social synchronization of brain activity increases during eye-contact.pdf}
}

@article{roqueRealTimeMobileEEG2025,
  title = {Real-{{Time Mobile EEG Hyperscanning}}: {{A Precise}} and {{Accessible Platform}} for {{Social Brain}}--{{Computer Interfaces}}},
  shorttitle = {Real-{{Time Mobile EEG Hyperscanning}}},
  author = {Roque, Thiago Rossi and Sun, Ruojia and Do, Yi Luen Ellen and Maldonado, Daniel Llamas and Leslie, Grace},
  year = {2025},
  journal = {IEEE Sensors Journal},
  pages = {1--1},
  issn = {1558-1748},
  doi = {10.1109/JSEN.2025.3597568},
  urldate = {2025-10-10},
  abstract = {This paper presents a cost-effective fully mobile EEG platform for reliable synchronous multi-brain imaging (hyperscanning) for social human-machine interactions, designed for both online and offline applications. We first quantify the error introduced when Lab Streaming Layer (LSL) is used as primary synchronization method on off-the-shelf mobile EEG systems: sampling-rate drifts and software latencies render conventional wireless hyperscanning techniques un-reliable. To overcome these limitations, we introduce a novel wireless hardware-trigger synchronization approach based on sub-1GHz technology with a customized acquisition software, leveraging affordable commercial wireless EEG (OpenBCI Cyton system) to achieve near-zero phase-delay synchronization while maintaining full mobility. The integrated hardware--software stack reduces online inter-device jitter to more than 1/10 of the original observed jitter, yielding a 99.3\% of accuracy in phase-locking value and spectral coherence during online measurement of synthetic 30 Hz signals. A mobile hyperscanning study on interpersonal behavioral synchronization (N = 8) validates ecological performance: significant inter-brain coupling was observed only during well-synchronized steps (p {$<$} 0.05, FWER-corrected). Finally, we demonstrate real-time visualization of inter-brain coupling using customized version of Vizaj, an open-source spatial networks visualization tool, confirming suitability for live neurofeedback. The proposed synchronization platform costs under \$100 for two heads, requires no cables between participants, and is readily adaptable to OpenBCI hardware. By releasing reproducible designs and code, this work lowers the barrier to group-level neurotechnology and paves the way for social brain-computer interfaces.},
  keywords = {brain-computer interface (BCI),Couplings,Delays,Electroencephalography,hyperscanning,mobile EEG,neurofeedback,Protocols,Real-time systems,Sensors,sensors synchronization,social interactions,social neuroscience,Software,Synchronization,Wireless communication,Wireless sensor networks},
  file = {/Users/au662726/Zotero/storage/5ZY7ZD7J/Roque et al. - 2025 - Real-Time Mobile EEG Hyperscanning A Precise and Accessible Platform for Social Brain–Computer Inte.pdf}
}

@misc{schultzLinkingLabsInterconnecting2021,
  title = {Linking {{Labs}}: {{Interconnecting Experimental Environments}}},
  shorttitle = {Linking {{Labs}}},
  author = {Schultz, Tanja and Putze, Felix and Fehr, Thorsten and Meier, Moritz and Mason, Celeste and Ahrens, Florian and Herrmann, Manfred},
  year = {2021},
  month = feb,
  number = {arXiv:2102.03684},
  eprint = {2102.03684},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2102.03684},
  urldate = {2025-10-10},
  abstract = {We introduce the concept of LabLinking: a technology-based interconnection of experimental laboratories across institutions, disciplines, cultures, languages, and time zones - in other words experiments without borders. In particular, we introduce LabLinking levels (LLL), which define the degree of tightness of empirical interconnection between labs. We describe the technological infrastructure in terms of hard- and software required for the respective LLLs and present examples of linked laboratories along with insights about the challenges and benefits. In sum, we argue that linked labs provide a unique platform for a continuous exchange between scientists and experimenters, thereby enabling a time synchronous execution of experiments performed with and by decentralized user and researchers, improving outreach and ease of subject recruitment, allowing to establish new experimental designs and to incorporate a panoply of complementary biosensors, devices, hard- and software solutions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Human-Computer Interaction},
  file = {/Users/au662726/Zotero/storage/M8RZQ8LZ/Schultz et al. - 2021 - Linking Labs Interconnecting Experimental Environments.pdf;/Users/au662726/Zotero/storage/V46T9ZQ8/2102.html}
}

@misc{stennerSccnLiblslV11622023,
  title = {Sccn/Liblsl: V1.16.2},
  shorttitle = {Sccn/Liblsl},
  author = {Stenner, Tristan and Boulay, Chadwick and Grivich, Matthew and Medine, David and Kothe, Christian and {Tobiasherzke} and {Chausner} and Grimm, Giso and {Xloem} and Biancarelli, Arthur and Mansencal, Boris and Maanen, Paul and Frey, J{\'e}r{\'e}my and {Jidong Chen} and {Kyucrane} and Powell, Samuel and Clisson, Pierre and {Phfix}},
  year = {2023},
  month = may,
  doi = {10.5281/ZENODO.5415958},
  urldate = {2025-09-19},
  abstract = {What's Changed Fix recovery issues by @tstenner in https://github.com/sccn/liblsl/pull/195 Fix lsl\_cpp.h exception handling by @jchen-dawnscene in https://github.com/sccn/liblsl/pull/194 Use native endianness for "portable" byte order by @tstenner in https://github.com/sccn/liblsl/pull/196 Add concurrency cancellation to GHA workflows. by @cboulay in https://github.com/sccn/liblsl/pull/197 New Contributors @jchen-dawnscene made their first contribution in https://github.com/sccn/liblsl/pull/194 {$<$}strong{$>$}Full Changelog{$<$}/strong{$>$}: https://github.com/sccn/liblsl/compare/v1.16.1...v1.16.2},
  copyright = {Open Access},
  howpublished = {Zenodo}
}

@article{stopczynskiSmartphoneBrainScanner2014,
  title = {The {{Smartphone Brain Scanner}}: {{A Portable Real-Time Neuroimaging System}}},
  shorttitle = {The {{Smartphone Brain Scanner}}},
  author = {Stopczynski, Arkadiusz and Stahlhut, Carsten and Larsen, Jakob Eg and Petersen, Michael Kai and Hansen, Lars Kai},
  year = {2014},
  month = feb,
  journal = {PLOS ONE},
  volume = {9},
  number = {2},
  pages = {e86733},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0086733},
  urldate = {2025-10-10},
  abstract = {Combining low-cost wireless EEG sensors with smartphones offers novel opportunities for mobile brain imaging in an everyday context. Here we present the technical details and validation of a framework for building multi-platform, portable EEG applications with real-time 3D source reconstruction. The system -- Smartphone Brain Scanner -- combines an off-the-shelf neuroheadset or EEG cap with a smartphone or tablet, and as such represents the first fully portable system for real-time 3D EEG imaging. We discuss the benefits and challenges, including technical limitations as well as details of real-time reconstruction of 3D images of brain activity. We present examples of brain activity captured in a simple experiment involving imagined finger tapping, which shows that the acquired signal in a relevant brain region is similar to that obtained with standard EEG lab equipment. Although the quality of the signal in a mobile solution using an off-the-shelf consumer neuroheadset is lower than the signal obtained using high-density standard EEG equipment, we propose mobile application development may offset the disadvantages and provide completely new opportunities for neuroimaging in natural settings.},
  langid = {english},
  keywords = {Cell phones,Computer software,Data acquisition,Data processing,Electroencephalography,Man-computer interface,Neuroimaging,Signal processing},
  file = {/Users/au662726/Zotero/storage/K94CF5LL/Stopczynski et al. - 2014 - The Smartphone Brain Scanner A Portable Real-Time Neuroimaging System.pdf}
}

@article{wangScopingReviewUse2023,
  title = {A Scoping Review of the Use of Lab Streaming Layer Framework in Virtual and Augmented Reality Research},
  author = {Wang, Qile and Zhang, Qinqi and Sun, Weitong and Boulay, Chadwick and Kim, Kangsoo and Barmaki, Roghayeh Leila},
  year = {2023},
  month = sep,
  journal = {Virtual Reality},
  volume = {27},
  number = {3},
  pages = {2195--2210},
  issn = {1434-9957},
  doi = {10.1007/s10055-023-00799-8},
  urldate = {2025-10-10},
  abstract = {The use of multimodal data allows excellent opportunities for human--computer interaction research and novel techniques regarding virtual and augmented reality (VR/AR) experiences. Collecting, coordinating, and synchronizing a large amount of data from multiple VR/AR hardware while maintaining a high framerate can be a daunting task, despite the compelling nature of multimodal data. The Lab Streaming Layer (LSL) is an open-source framework that enables the synchronous collection of various types of multimodal data, unlike existing expensive alternatives. However, despite its potential, this framework has not been fully adopted by the VR/AR research community. In this paper, we present a guideline of the LSL framework's use in VR/AR research as well as report current trends by performing a comprehensive literature review on the subject. We extract 549 publications using LSL from January 2015 to March 2022. We analyze types of data, displays, and targeted application areas. We describe in-depth reviews of 38 selected papers and provide use of LSL in the VR/AR research community while highlighting benefits, challenges, and future opportunities.},
  langid = {english},
  keywords = {Augmented reality,Lab Streaming layer,Literature review,Multimodal data collection,Open-source data collection,Virtual reality},
  file = {/Users/au662726/Zotero/storage/ZANV2CIR/Wang et al. - 2023 - A scoping review of the use of lab streaming layer framework in virtual and augmented reality resear.pdf}
}

@article{zammPracticalGuideEEG2024b,
  title = {A Practical Guide to {{EEG}} Hyperscanning in Joint Action Research: From Motivation to Implementation},
  shorttitle = {A Practical Guide to {{EEG}} Hyperscanning in Joint Action Research},
  author = {Zamm, Anna and Loehr, Janeen D and Vesper, Cordula and Konvalinka, Ivana and Kappel, Simon L and Heggli, Ole A and Vuust, Peter and Keller, Peter E},
  year = {2024},
  month = may,
  journal = {Social Cognitive and Affective Neuroscience},
  volume = {19},
  number = {1},
  pages = {nsae026},
  issn = {1749-5016, 1749-5024},
  doi = {10.1093/scan/nsae026},
  urldate = {2025-09-19},
  abstract = {Abstract             Developments in cognitive neuroscience have led to the emergence of hyperscanning, the simultaneous measurement of brain activity from multiple people. Hyperscanning is useful for investigating social cognition, including joint action, because of its ability to capture neural processes that occur within and between people as they coordinate actions toward a shared goal. Here, we provide a practical guide for researchers considering using hyperscanning to study joint action and seeking to avoid frequently raised concerns from hyperscanning skeptics. We focus specifically on Electroencephalography (EEG) hyperscanning, which is widely available and optimally suited for capturing fine-grained temporal dynamics of action coordination. Our guidelines cover questions that are likely to arise when planning a hyperscanning project, ranging from whether hyperscanning is appropriate for answering one's research questions to considerations for study design, dependent variable selection, data analysis and visualization. By following clear guidelines that facilitate careful consideration of the theoretical implications of research design choices and other methodological decisions, joint action researchers can mitigate interpretability issues and maximize the benefits of hyperscanning paradigms.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/au662726/Zotero/storage/NVP37P2P/Zamm et al. - 2024 - A practical guide to EEG hyperscanning in joint action research from motivation to implementation.pdf}
}
