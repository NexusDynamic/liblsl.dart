@article{dolmans2020data,
  title = {Data Synchronisation and Processing in Multimodal Research},
  author = {Dolmans, {\relax TC} and Poel, M and {van't Klooster}, {\relax JWJR} and Veldkamp, {\relax BP}},
  year = {2020},
  journal = {Measuring Behavior 2020-21 Volume},
  volume = {1},
  pages = {26--32}
}

@article{iwamaTwoCommonIssues2024,
  title = {Two Common Issues in Synchronized Multimodal Recordings with {{EEG}}: {{Jitter}} and Latency},
  shorttitle = {Two Common Issues in Synchronized Multimodal Recordings with {{EEG}}},
  author = {Iwama, Seitaro and Takemi, Mitsuaki and Eguchi, Ryo and Hirose, Ryotaro and Morishige, Masumi and Ushiba, Junichi},
  year = {2024},
  month = jun,
  journal = {Neuroscience Research},
  volume = {203},
  pages = {1--7},
  issn = {01680102},
  doi = {10.1016/j.neures.2023.12.003},
  urldate = {2025-09-19},
  langid = {english},
  file = {/Users/au662726/Zotero/storage/DLE6QY6E/Iwama et al. - 2024 - Two common issues in synchronized multimodal recordings with EEG Jitter and latency.pdf}
}

@article{kotheLabStreamingLayer2025,
  title = {The Lab Streaming Layer for Synchronized Multimodal Recording},
  author = {Kothe, Christian and Shirazi, Seyed Yahya and Stenner, Tristan and Medine, David and Boulay, Chadwick and Grivich, Matthew I. and Artoni, Fiorenzo and Mullen, Tim and Delorme, Arnaud and Makeig, Scott},
  year = {2025},
  month = sep,
  journal = {Imaging Neuroscience},
  volume = {3},
  pages = {IMAG.a.136},
  issn = {2837-6056},
  doi = {10.1162/IMAG.a.136},
  urldate = {2025-09-19},
  abstract = {Abstract             Accurately recording the interactions of humans or other organisms with their environment and other agents requires synchronized data access via multiple instruments, often running independently using different clocks. Active, hardware-mediated solutions are often infeasible or prohibitively costly to build and run across arbitrary collections of input systems. The Lab Streaming Layer (LSL) framework offers a software-based approach to synchronizing data streams based on per-sample time stamps and time synchronization across a common local area network (LAN). Built from the ground up for neurophysiological applications and designed for reliability, LSL offers zero-configuration functionality and accounts for network delays and jitters, making connection recovery, offset correction, and jitter compensation possible. These features can ensure continuous, millisecond-precise data recording, even in the face of interruptions. In this paper, we present an overview of LSL architecture, core features, and performance in common experimental contexts. We also highlight practical considerations and known pitfalls when using LSL, including the need to take into account input device throughput delays that LSL cannot itself measure or correct. The LSL ecosystem has grown to support over 150 data acquisition device classes and to establish interoperability between client software written in several programming languages, including C/C++, Python, MATLAB, Java, C\#, JavaScript, Rust, and Julia. The resilience and versatility of LSL have made it a major data synchronization platform for multimodal human neurobehavioral recording, now supported by a wide range of software packages, including major stimulus presentation tools, real-time analysis environments, and brain-computer interface applications. Beyond basic science, research, and development, LSL has been used as a resilient and transparent back-end in deployment scenarios, including interactive art installations, stage performances, and commercial products. In neurobehavioral studies and other neuroscience applications, LSL facilitates the complex task of capturing organismal dynamics and environmental changes occurring within and across multiple data streams on a common timeline.},
  langid = {english}
}

@misc{LiblslLanguageWrappers,
  title = {Liblsl Language Wrappers --- {{Labstreaminglayer}} 1.13 Documentation},
  author = {Kothe, Christian and Medine, David and Boulay, Chadwick and Grivich, Matthew and Stenner, Tristan},
  year = {2019},
  urldate = {2025-09-23},
  howpublished = {https://labstreaminglayer.readthedocs.io/info/language\_wrappers.html},
  file = {/Users/au662726/Zotero/storage/LD2HD6RJ/language_wrappers.html}
}

@misc{stennerSccnLiblslV11622023,
  title = {Sccn/Liblsl: V1.16.2},
  shorttitle = {Sccn/Liblsl},
  author = {Stenner, Tristan and Boulay, Chadwick and Grivich, Matthew and Medine, David and Kothe, Christian and {Tobiasherzke} and {Chausner} and Grimm, Giso and {Xloem} and Biancarelli, Arthur and Mansencal, Boris and Maanen, Paul and Frey, J{\'e}r{\'e}my and {Jidong Chen} and {Kyucrane} and Powell, Samuel and Clisson, Pierre and {Phfix}},
  year = {2023},
  month = may,
  doi = {10.5281/ZENODO.5415958},
  urldate = {2025-09-19},
  abstract = {What's Changed Fix recovery issues by @tstenner in https://github.com/sccn/liblsl/pull/195 Fix lsl\_cpp.h exception handling by @jchen-dawnscene in https://github.com/sccn/liblsl/pull/194 Use native endianness for "portable" byte order by @tstenner in https://github.com/sccn/liblsl/pull/196 Add concurrency cancellation to GHA workflows. by @cboulay in https://github.com/sccn/liblsl/pull/197 New Contributors @jchen-dawnscene made their first contribution in https://github.com/sccn/liblsl/pull/194 {$<$}strong{$>$}Full Changelog{$<$}/strong{$>$}: https://github.com/sccn/liblsl/compare/v1.16.1...v1.16.2},
  copyright = {Open Access},
  howpublished = {Zenodo}
}

@article{zammPracticalGuideEEG2024b,
  title = {A Practical Guide to {{EEG}} Hyperscanning in Joint Action Research: From Motivation to Implementation},
  shorttitle = {A Practical Guide to {{EEG}} Hyperscanning in Joint Action Research},
  author = {Zamm, Anna and Loehr, Janeen D and Vesper, Cordula and Konvalinka, Ivana and Kappel, Simon L and Heggli, Ole A and Vuust, Peter and Keller, Peter E},
  year = {2024},
  month = may,
  journal = {Social Cognitive and Affective Neuroscience},
  volume = {19},
  number = {1},
  pages = {nsae026},
  issn = {1749-5016, 1749-5024},
  doi = {10.1093/scan/nsae026},
  urldate = {2025-09-19},
  abstract = {Abstract             Developments in cognitive neuroscience have led to the emergence of hyperscanning, the simultaneous measurement of brain activity from multiple people. Hyperscanning is useful for investigating social cognition, including joint action, because of its ability to capture neural processes that occur within and between people as they coordinate actions toward a shared goal. Here, we provide a practical guide for researchers considering using hyperscanning to study joint action and seeking to avoid frequently raised concerns from hyperscanning skeptics. We focus specifically on Electroencephalography (EEG) hyperscanning, which is widely available and optimally suited for capturing fine-grained temporal dynamics of action coordination. Our guidelines cover questions that are likely to arise when planning a hyperscanning project, ranging from whether hyperscanning is appropriate for answering one's research questions to considerations for study design, dependent variable selection, data analysis and visualization. By following clear guidelines that facilitate careful consideration of the theoretical implications of research design choices and other methodological decisions, joint action researchers can mitigate interpretability issues and maximize the benefits of hyperscanning paradigms.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/au662726/Zotero/storage/NVP37P2P/Zamm et al. - 2024 - A practical guide to EEG hyperscanning in joint action research from motivation to implementation.pdf}
}
